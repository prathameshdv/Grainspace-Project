{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prathameshdv/Grainspace-Project/blob/main/Grainspace%3AEnsemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "ZIP_NAME = \"WHEAT_R19-22_G600_TRAIN.zip\"   # change to your uploaded zip filename\n",
        "UNZIP_DIR = Path(\"wheat_R19_22_G600/train\")   # where zip will extract\n",
        "SPLIT_DIR = Path(\"wheat_R19_22_G600_split\")  # output split folder\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Training options\n",
        "PRETRAINED = True   # If True -> ImageNet pretrained ConvNeXt, else random init (scratch)\n",
        "MODEL_NAME = \"convnext_tiny\"  # \"convnext_tiny\" recommended; you can also try convnext_base if you have memory\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "LR = 0.015\n",
        "WEIGHT_DECAY = 1e-4\n",
        "MILESTONES = [15, 25]  # lr scheduler step-down epochs or use StepLR below\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_WORKERS = 4\n",
        "SAVE_BEST = True\n",
        "BEST_MODEL_PATH = \"best_convnext.pth\"\n",
        "\n",
        "print(\"Device:\", DEVICE)\n"
      ],
      "metadata": {
        "id": "hHvr5us8znWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSxv4grZzg5y"
      },
      "outputs": [],
      "source": [
        "rom zipfile import ZipFile\n",
        "\n",
        "if not UNZIP_DIR.exists():\n",
        "    print(\"Unzipping:\", ZIP_NAME)\n",
        "    assert Path(ZIP_NAME).exists(), f\"{ZIP_NAME} not found in current directory!\"\n",
        "    with ZipFile(ZIP_NAME, 'r') as zip_ref:\n",
        "        zip_ref.extractall(UNZIP_DIR)\n",
        "    print(\"Extracted to\", UNZIP_DIR)\n",
        "else:\n",
        "    print(\"Unzip target already exists:\", UNZIP_DIR)\n",
        "\n",
        "# quick listing\n",
        "print(\"Top-level folders (classes):\", sorted([p.name for p in UNZIP_DIR.iterdir() if p.is_dir()]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "def make_splits(src_dir: Path, out_dir: Path, train_frac=0.8, val_frac=0.1):\n",
        "    if out_dir.exists():\n",
        "        print(\"Split dir exists, removing and recreating:\", out_dir)\n",
        "        shutil.rmtree(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        (out_dir / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for class_dir in sorted(src_dir.iterdir()):\n",
        "        if not class_dir.is_dir():\n",
        "            continue\n",
        "        imgs = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\")) + list(class_dir.glob(\"*.jpeg\"))\n",
        "        if len(imgs) == 0:\n",
        "            print(f\"Warning: no images found in {class_dir}\")\n",
        "            continue\n",
        "        random.shuffle(imgs)\n",
        "        n = len(imgs)\n",
        "        n_train = int(train_frac * n)\n",
        "        n_val = int(val_frac * n)\n",
        "        n_test = n - n_train - n_val\n",
        "        splits = {\n",
        "            \"train\": imgs[:n_train],\n",
        "            \"val\": imgs[n_train:n_train+n_val],\n",
        "            \"test\": imgs[n_train+n_val:]\n",
        "        }\n",
        "        for sp, files in splits.items():\n",
        "            tgt_dir = out_dir / sp / class_dir.name\n",
        "            tgt_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for f in files:\n",
        "                # copy (keeps original intact)\n",
        "                shutil.copy(f, tgt_dir / f.name)\n",
        "    print(\"Done creating splits at:\", out_dir)\n",
        "\n",
        "make_splits(UNZIP_DIR, SPLIT_DIR)"
      ],
      "metadata": {
        "id": "shyUlCMvzw7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def counts(split_dir: Path):\n",
        "    info = {}\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        split_path = split_dir / split\n",
        "        if not split_path.exists():\n",
        "            info[split] = 0\n",
        "            continue\n",
        "        total = 0\n",
        "        per_class = {}\n",
        "        for cls in sorted([d for d in split_path.iterdir() if d.is_dir()]):\n",
        "            c = len(list(cls.glob(\"*.*\")))\n",
        "            per_class[cls.name] = c\n",
        "            total += c\n",
        "        info[split] = {\"total\": total, \"per_class\": per_class}\n",
        "    return info\n",
        "\n",
        "cnts = counts(SPLIT_DIR)\n",
        "print(\"Train total:\", cnts[\"train\"][\"total\"])\n",
        "print(\"Val total:\", cnts[\"val\"][\"total\"])\n",
        "print(\"Test total:\", cnts[\"test\"][\"total\"])\n",
        "print(\"Per-class counts (train):\")\n",
        "for k,v in cnts[\"train\"][\"per_class\"].items():\n",
        "    print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "id": "O3zxYN55zxHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "train_dataset = ImageFolder(str(SPLIT_DIR/\"train\"), transform=train_transform)\n",
        "val_dataset = ImageFolder(str(SPLIT_DIR/\"val\"), transform=val_test_transform)\n",
        "test_dataset = ImageFolder(str(SPLIT_DIR/\"test\"), transform=val_test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(\"Num classes:\", num_classes, \"Class names:\", class_names)\n",
        "print(\"Train/Val/Test sizes:\", len(train_dataset), len(val_dataset), len(test_dataset))\n"
      ],
      "metadata": {
        "id": "99Gv12C2zxO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet50(num_classes, pretrained=True):\n",
        "    try:\n",
        "        model = torchvision.models.resnet50(pretrained=pretrained)\n",
        "    except:\n",
        "        weights = torchvision.models.ResNet50_Weights.DEFAULT if pretrained else None\n",
        "        model = torchvision.models.resnet50(weights=weights)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def build_convnext(num_classes, pretrained=True):\n",
        "    try:\n",
        "        model = torchvision.models.convnext_tiny(pretrained=pretrained)\n",
        "    except:\n",
        "        weights = torchvision.models.ConvNeXt_Tiny_Weights.DEFAULT if pretrained else None\n",
        "        model = torchvision.models.convnext_tiny(weights=weights)\n",
        "    model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "resnet = build_resnet50(num_classes, pretrained=PRETRAINED).to(DEVICE)\n",
        "convnext = build_convnext(num_classes, pretrained=PRETRAINED).to(DEVICE)"
      ],
      "metadata": {
        "id": "bijy5EpMzxVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs, lr):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    best_val_f1 = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(imgs)\n",
        "                preds = outputs.argmax(1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        val_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Val Macro F1: {val_f1:.4f}\")\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_state = model.state_dict().copy()\n",
        "    model.load_state_dict(best_state)\n",
        "    return model"
      ],
      "metadata": {
        "id": "jC_0ScY_zxbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training ResNet-50...\")\n",
        "resnet = train_model(resnet, train_loader, val_loader, epochs=EPOCHS, lr=LR)\n",
        "\n",
        "print(\"\\nTraining ConvNeXt-Tiny...\")\n",
        "convnext = train_model(convnext, train_loader, val_loader, epochs=EPOCHS, lr=LR)\n"
      ],
      "metadata": {
        "id": "mAdeoEcYzxhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ensemble(models, loader):\n",
        "    for m in models: m.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            logits = [m(imgs) for m in models]\n",
        "            avg_logits = sum(logits) / len(logits)\n",
        "            preds = avg_logits.argmax(1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    return macro_f1, all_preds, all_labels\n",
        "\n",
        "test_f1, preds, labels = evaluate_ensemble([resnet, convnext], test_loader)\n",
        "print(f\" Ensemble (ResNet+ConvNeXt) Test Macro F1: {test_f1:.4f}\")\n",
        "print(classification_report(labels, preds, target_names=class_names, digits=4))"
      ],
      "metadata": {
        "id": "M3Edgv050FLz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}